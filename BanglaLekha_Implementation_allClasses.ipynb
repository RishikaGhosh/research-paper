{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP0ab1PRtThWseyDRBu7u2d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RishikaGhosh/research-paper/blob/master/BanglaLekha_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRx9b3KMt6v0",
        "outputId": "9fc0ec6d-62c5-4dba-9364-db89a0af8720"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip drive/MyDrive/BanglaLekha-Isolated> /dev/null"
      ],
      "metadata": {
        "id": "5KgaVvYKueIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y66fe04MueGG",
        "outputId": "2cda0e72-13d5-423c-8a24-56de4f0a031d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.20.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIG1gVzHueBi",
        "outputId": "63144863-2e5a-4455-cab6-86e4d89c881e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.10/dist-packages (0.20.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.1)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (2.13.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "import os\n",
        "import cv2\n",
        "from PIL import ImageFile,Image\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Conv2D, MaxPooling2D, Reshape, LSTM\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "1OGb8AH4ud_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install split-folders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb-CUo2tud80",
        "outputId": "c2fc37a8-2b7a-46b3-d7c0-129164c9d7d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_set = \"BanglaLekha-Isolated/Images\"\n",
        "dimensions = (28, 28)"
      ],
      "metadata": {
        "id": "UPW5UauDud6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_images(folder):\n",
        "\n",
        "    classes = [os.path.join(folder, d) for d in sorted(os.listdir(folder))]  # get list of all sub-folders in folder\n",
        "    img_cnt = 0\n",
        "    i=0\n",
        "    for class_x in classes:\n",
        "        i=i+1\n",
        "        if os.path.isdir(class_x):\n",
        "\n",
        "            # get paths to all the images in this folder\n",
        "            images = [os.path.join(class_x, i) for i in sorted(os.listdir(class_x)) if i != '.DS_Store']\n",
        "            print(len(images))\n",
        "            if folder == \"Dataset/Test\" and i==1:\n",
        "                images = images[:-1]\n",
        "\n",
        "            for image in images:\n",
        "\n",
        "                img_cnt = img_cnt + 1\n",
        "\n",
        "                if(img_cnt % 1000 == 0):                # show progress\n",
        "                    print(\"Processed %s images\" % str(img_cnt))\n",
        "\n",
        "                im = Image.open(image)\n",
        "                print(image)\n",
        "                im = im.resize(dimensions)   # resize image according to dimensions set\n",
        "\n",
        "                im = im.convert('L')\n",
        "\n",
        "                image_array = np.array(im)\n",
        "                otsu_threshold, image_result = cv2.threshold(image_array, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
        "                im = Image.fromarray(image_result)\n",
        "\n",
        "                im.save(image)\n",
        "    print(\"Finished processing images, images found = \")\n",
        "    print(img_cnt)\n",
        "process_images(data_set)"
      ],
      "metadata": {
        "id": "LKxjci2Eud3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install split-folders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luYKt_sCudzU",
        "outputId": "97b8c9e0-64e0-4b3a-edb3-9e04f8ca66ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: split-folders in /usr/local/lib/python3.10/dist-packages (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders"
      ],
      "metadata": {
        "id": "nm8JQA0gudnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splitfolders.ratio(\"/content/BanglaLekha-Isolated/Images\", output=\"BanglaLekha_dataset\",\n",
        "    seed=1337, ratio=(.7,.1,.2), group_prefix=None, move=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhcvffoDyiFv",
        "outputId": "c45b5809-6b57-44ec-8b31-1de06e26c104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 166105 files [00:20, 8298.25 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = Sequential()\n",
        "\n",
        "classifier.add(Conv2D(filters = 32, kernel_size = (3, 3), strides = (1,1), padding = \"same\", input_shape = (28, 28, 1)))\n",
        "classifier.add(tf.keras.layers.LeakyReLU(alpha=0.1))\n",
        "classifier.add(BatchNormalization())\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2), padding = \"valid\"))\n",
        "classifier.add(Dropout(.2))\n",
        "\n",
        "classifier.add(Conv2D(filters = 64, kernel_size = (3, 3), strides = (1,1), padding = \"same\"))\n",
        "classifier.add(tf.keras.layers.LeakyReLU(alpha=0.1))\n",
        "classifier.add(BatchNormalization())\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2), padding = \"valid\"))\n",
        "classifier.add(Dropout(.2))\n",
        "\n",
        "classifier.add(Conv2D(filters = 128, kernel_size = (3, 3), strides = (1,1), padding = \"same\"))\n",
        "classifier.add(tf.keras.layers.LeakyReLU(alpha=0.1))\n",
        "classifier.add(BatchNormalization())\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2), padding = \"valid\"))\n",
        "classifier.add(Dropout(.2))\n",
        "\n",
        "classifier.add(Reshape((3,3*128),input_shape=(3,3,128)))\n",
        "classifier.add(LSTM(128, return_sequences=True))\n",
        "\n",
        "classifier.add(Flatten())\n",
        "\n",
        "classifier.add(Dense(units = 128))\n",
        "classifier.add(tf.keras.layers.LeakyReLU(alpha=0.1))\n",
        "classifier.add(Dropout(.2))\n",
        "\n",
        "classifier.add(Dense(units = 64))\n",
        "classifier.add(tf.keras.layers.LeakyReLU(alpha=0.1))\n",
        "classifier.add(Dropout(.2))\n",
        "\n",
        "classifier.add(Dense(units = 50, activation = 'softmax'))\n",
        "\n",
        "opt=tf.keras.optimizers.Adadelta(learning_rate=0.1, rho=0.95)              \n",
        "classifier.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "-oxXyX5VyiEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = Sequential()\n",
        "\n",
        "classifier.add(Conv2D(filters = 32, kernel_size = (3, 3), strides = (1,1), padding = \"same\", input_shape = (28, 28, 1)))\n",
        "classifier.add(tf.keras.layers.LeakyReLU(alpha=0.1))\n",
        "classifier.add(BatchNormalization())\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2), padding = \"valid\"))\n",
        "classifier.add(Dropout(.2))\n",
        "\n",
        "classifier.add(Conv2D(filters = 64, kernel_size = (3, 3), strides = (1,1), padding = \"same\"))\n",
        "classifier.add(tf.keras.layers.LeakyReLU(alpha=0.1))\n",
        "classifier.add(BatchNormalization())\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2), padding = \"valid\"))\n",
        "classifier.add(Dropout(.2))\n",
        "\n",
        "classifier.add(Conv2D(filters = 128, kernel_size = (3, 3), strides = (1,1), padding = \"same\"))\n",
        "classifier.add(tf.keras.layers.LeakyReLU(alpha=0.1))\n",
        "classifier.add(BatchNormalization())\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2), padding = \"valid\"))\n",
        "classifier.add(Dropout(.2))\n",
        "\n",
        "classifier.add(Reshape((3,3*128),input_shape=(3,3,128)))\n",
        "classifier.add(LSTM(128, return_sequences=True))\n",
        "\n",
        "classifier.add(Flatten())\n",
        "\n",
        "classifier.add(Dense(units = 128))\n",
        "classifier.add(tf.keras.layers.LeakyReLU(alpha=0.1))\n",
        "classifier.add(Dropout(.2))\n",
        "\n",
        "classifier.add(Dense(units = 64))\n",
        "classifier.add(tf.keras.layers.LeakyReLU(alpha=0.1))\n",
        "classifier.add(Dropout(.2))\n",
        "\n",
        "classifier.add(Dense(units = 84, activation = 'softmax'))\n",
        "\n",
        "opt=tf.keras.optimizers.Adadelta(learning_rate=0.1, rho=0.95)              \n",
        "classifier.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "SEmwHO21KuCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cn97_nrmyiBr",
        "outputId": "3dfd23db-40d6-41fe-9110-0c545308d2fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " leaky_re_lu_10 (LeakyReLU)  (None, 28, 28, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 28, 28, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 14, 14, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 14, 14, 32)        0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 14, 14, 64)        18496     \n",
            "                                                                 \n",
            " leaky_re_lu_11 (LeakyReLU)  (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 14, 14, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 7, 7, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 7, 7, 128)         73856     \n",
            "                                                                 \n",
            " leaky_re_lu_12 (LeakyReLU)  (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 7, 7, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 3, 3, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 3, 3, 128)         0         \n",
            "                                                                 \n",
            " reshape_2 (Reshape)         (None, 3, 384)            0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 3, 128)            262656    \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 384)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               49280     \n",
            "                                                                 \n",
            " leaky_re_lu_13 (LeakyReLU)  (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " leaky_re_lu_14 (LeakyReLU)  (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 84)                5460      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 419,220\n",
            "Trainable params: 418,772\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_folder = \"/content/BanglaLekha_dataset/train\"\n",
        "val_folder = \"/content/BanglaLekha_dataset/val\"\n",
        "test_folder = \"/content/BanglaLekha_dataset/test\""
      ],
      "metadata": {
        "id": "Obccajwpyh_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "XA4JNNbIyh46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(shear_range = .2, rotation_range = 25)\n",
        "val_datagen = ImageDataGenerator()\n",
        "test_datagen = ImageDataGenerator()\n",
        "\n",
        "train_set = train_datagen.flow_from_directory(train_folder, target_size = (28, 28), \n",
        "                                                 batch_size = 32, class_mode = 'categorical',color_mode=\"grayscale\")\n",
        "val_set = val_datagen.flow_from_directory(val_folder, target_size = (28, 28), \n",
        "                                                 batch_size = 32, class_mode = 'categorical',color_mode=\"grayscale\")\n",
        "test_set = test_datagen.flow_from_directory(test_folder, target_size = (28, 28), \n",
        "                                                 batch_size = 32, class_mode = 'categorical',color_mode=\"grayscale\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUDgnzkOzEwN",
        "outputId": "62398d63-7f26-4aa1-92b0-25beac9fccbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 116237 images belonging to 84 classes.\n",
            "Found 16579 images belonging to 84 classes.\n",
            "Found 33289 images belonging to 84 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=classifier.fit(train_set, steps_per_epoch = len(train_set), epochs = 50,\n",
        "                        validation_data = val_set, validation_steps = len(val_set))\n",
        "classifier.save_weights('train_weights1.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smqAHvAizcTm",
        "outputId": "de27eaf1-a031-4472-d3b4-95ed4741b343"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "3633/3633 [==============================] - 92s 24ms/step - loss: 3.6126 - accuracy: 0.1346 - val_loss: 2.3797 - val_accuracy: 0.3942\n",
            "Epoch 2/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 2.4132 - accuracy: 0.3481 - val_loss: 1.5083 - val_accuracy: 0.5992\n",
            "Epoch 3/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 1.8665 - accuracy: 0.4753 - val_loss: 1.1553 - val_accuracy: 0.6826\n",
            "Epoch 4/50\n",
            "3633/3633 [==============================] - 86s 24ms/step - loss: 1.5626 - accuracy: 0.5552 - val_loss: 0.9375 - val_accuracy: 0.7459\n",
            "Epoch 5/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 1.3649 - accuracy: 0.6093 - val_loss: 0.8605 - val_accuracy: 0.7601\n",
            "Epoch 6/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 1.2299 - accuracy: 0.6494 - val_loss: 0.7826 - val_accuracy: 0.7831\n",
            "Epoch 7/50\n",
            "3633/3633 [==============================] - 86s 24ms/step - loss: 1.1247 - accuracy: 0.6793 - val_loss: 0.7167 - val_accuracy: 0.7993\n",
            "Epoch 8/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 1.0507 - accuracy: 0.7025 - val_loss: 0.6614 - val_accuracy: 0.8143\n",
            "Epoch 9/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.9875 - accuracy: 0.7194 - val_loss: 0.6257 - val_accuracy: 0.8256\n",
            "Epoch 10/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.9360 - accuracy: 0.7349 - val_loss: 0.5964 - val_accuracy: 0.8321\n",
            "Epoch 11/50\n",
            "3633/3633 [==============================] - 89s 24ms/step - loss: 0.8967 - accuracy: 0.7465 - val_loss: 0.5868 - val_accuracy: 0.8365\n",
            "Epoch 12/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.8586 - accuracy: 0.7578 - val_loss: 0.5718 - val_accuracy: 0.8415\n",
            "Epoch 13/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.8286 - accuracy: 0.7677 - val_loss: 0.5466 - val_accuracy: 0.8490\n",
            "Epoch 14/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.8023 - accuracy: 0.7744 - val_loss: 0.5472 - val_accuracy: 0.8490\n",
            "Epoch 15/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.7751 - accuracy: 0.7813 - val_loss: 0.5202 - val_accuracy: 0.8564\n",
            "Epoch 16/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.7580 - accuracy: 0.7880 - val_loss: 0.5316 - val_accuracy: 0.8527\n",
            "Epoch 17/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.7361 - accuracy: 0.7932 - val_loss: 0.5064 - val_accuracy: 0.8599\n",
            "Epoch 18/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.7218 - accuracy: 0.7968 - val_loss: 0.5152 - val_accuracy: 0.8563\n",
            "Epoch 19/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.7006 - accuracy: 0.8031 - val_loss: 0.5222 - val_accuracy: 0.8558\n",
            "Epoch 20/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.6882 - accuracy: 0.8070 - val_loss: 0.4979 - val_accuracy: 0.8635\n",
            "Epoch 21/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.6799 - accuracy: 0.8097 - val_loss: 0.4994 - val_accuracy: 0.8613\n",
            "Epoch 22/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.6677 - accuracy: 0.8141 - val_loss: 0.4786 - val_accuracy: 0.8694\n",
            "Epoch 23/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.6592 - accuracy: 0.8152 - val_loss: 0.4804 - val_accuracy: 0.8675\n",
            "Epoch 24/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.6472 - accuracy: 0.8198 - val_loss: 0.4750 - val_accuracy: 0.8695\n",
            "Epoch 25/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.6327 - accuracy: 0.8231 - val_loss: 0.4661 - val_accuracy: 0.8716\n",
            "Epoch 26/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.6271 - accuracy: 0.8252 - val_loss: 0.4736 - val_accuracy: 0.8723\n",
            "Epoch 27/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.6243 - accuracy: 0.8267 - val_loss: 0.4654 - val_accuracy: 0.8733\n",
            "Epoch 28/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.6113 - accuracy: 0.8300 - val_loss: 0.4576 - val_accuracy: 0.8772\n",
            "Epoch 29/50\n",
            "3633/3633 [==============================] - 90s 25ms/step - loss: 0.6077 - accuracy: 0.8317 - val_loss: 0.4565 - val_accuracy: 0.8761\n",
            "Epoch 30/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.5967 - accuracy: 0.8343 - val_loss: 0.4592 - val_accuracy: 0.8760\n",
            "Epoch 31/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.5945 - accuracy: 0.8355 - val_loss: 0.4520 - val_accuracy: 0.8768\n",
            "Epoch 32/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.5824 - accuracy: 0.8373 - val_loss: 0.4482 - val_accuracy: 0.8779\n",
            "Epoch 33/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.5778 - accuracy: 0.8403 - val_loss: 0.4509 - val_accuracy: 0.8783\n",
            "Epoch 34/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.5688 - accuracy: 0.8412 - val_loss: 0.4443 - val_accuracy: 0.8807\n",
            "Epoch 35/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.5677 - accuracy: 0.8431 - val_loss: 0.4455 - val_accuracy: 0.8820\n",
            "Epoch 36/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.5665 - accuracy: 0.8433 - val_loss: 0.4424 - val_accuracy: 0.8815\n",
            "Epoch 37/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.5557 - accuracy: 0.8456 - val_loss: 0.4376 - val_accuracy: 0.8833\n",
            "Epoch 38/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.5519 - accuracy: 0.8463 - val_loss: 0.4391 - val_accuracy: 0.8847\n",
            "Epoch 39/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.5488 - accuracy: 0.8477 - val_loss: 0.4415 - val_accuracy: 0.8841\n",
            "Epoch 40/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.5457 - accuracy: 0.8486 - val_loss: 0.4326 - val_accuracy: 0.8851\n",
            "Epoch 41/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.5371 - accuracy: 0.8501 - val_loss: 0.4393 - val_accuracy: 0.8836\n",
            "Epoch 42/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.5387 - accuracy: 0.8505 - val_loss: 0.4350 - val_accuracy: 0.8865\n",
            "Epoch 43/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.5308 - accuracy: 0.8531 - val_loss: 0.4341 - val_accuracy: 0.8873\n",
            "Epoch 44/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.5318 - accuracy: 0.8515 - val_loss: 0.4355 - val_accuracy: 0.8874\n",
            "Epoch 45/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.5261 - accuracy: 0.8545 - val_loss: 0.4291 - val_accuracy: 0.8862\n",
            "Epoch 46/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.5245 - accuracy: 0.8543 - val_loss: 0.4291 - val_accuracy: 0.8889\n",
            "Epoch 47/50\n",
            "3633/3633 [==============================] - 90s 25ms/step - loss: 0.5212 - accuracy: 0.8550 - val_loss: 0.4297 - val_accuracy: 0.8885\n",
            "Epoch 48/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.5168 - accuracy: 0.8567 - val_loss: 0.4261 - val_accuracy: 0.8893\n",
            "Epoch 49/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.5132 - accuracy: 0.8585 - val_loss: 0.4323 - val_accuracy: 0.8876\n",
            "Epoch 50/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.5153 - accuracy: 0.8574 - val_loss: 0.4206 - val_accuracy: 0.8909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.evaluate(test_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdwn7I4zAznR",
        "outputId": "f48e837f-fa79-46a0-e1c7-0e4e1e18b9b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1041/1041 [==============================] - 11s 11ms/step - loss: 0.3709 - accuracy: 0.9018\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.37085238099098206, 0.9017993807792664]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.load_weights('train_weights1.h5')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=5, min_lr=0.001)\n",
        "history1=classifier.fit(train_set, steps_per_epoch = len(train_set), epochs = 50,\n",
        "                        validation_data = val_set, validation_steps = len(val_set),callbacks=[reduce_lr])\n",
        "classifier.save_weights('train_weights2.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXK4WH7Vzb-T",
        "outputId": "bfcd822a-e54f-4231-ae87-75133e9936e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.5097 - accuracy: 0.8589 - val_loss: 0.4229 - val_accuracy: 0.8887 - lr: 0.1000\n",
            "Epoch 2/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.5066 - accuracy: 0.8606 - val_loss: 0.4308 - val_accuracy: 0.8883 - lr: 0.1000\n",
            "Epoch 3/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.5045 - accuracy: 0.8624 - val_loss: 0.4258 - val_accuracy: 0.8884 - lr: 0.1000\n",
            "Epoch 4/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.5021 - accuracy: 0.8614 - val_loss: 0.4260 - val_accuracy: 0.8893 - lr: 0.1000\n",
            "Epoch 5/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.5011 - accuracy: 0.8615 - val_loss: 0.4245 - val_accuracy: 0.8909 - lr: 0.1000\n",
            "Epoch 6/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4962 - accuracy: 0.8627 - val_loss: 0.4316 - val_accuracy: 0.8881 - lr: 0.1000\n",
            "Epoch 7/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4857 - accuracy: 0.8656 - val_loss: 0.4189 - val_accuracy: 0.8919 - lr: 0.0200\n",
            "Epoch 8/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4787 - accuracy: 0.8676 - val_loss: 0.4198 - val_accuracy: 0.8920 - lr: 0.0200\n",
            "Epoch 9/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4770 - accuracy: 0.8680 - val_loss: 0.4199 - val_accuracy: 0.8918 - lr: 0.0200\n",
            "Epoch 10/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4748 - accuracy: 0.8681 - val_loss: 0.4193 - val_accuracy: 0.8924 - lr: 0.0200\n",
            "Epoch 11/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4738 - accuracy: 0.8688 - val_loss: 0.4178 - val_accuracy: 0.8925 - lr: 0.0200\n",
            "Epoch 12/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4733 - accuracy: 0.8685 - val_loss: 0.4178 - val_accuracy: 0.8925 - lr: 0.0200\n",
            "Epoch 13/50\n",
            "3633/3633 [==============================] - 90s 25ms/step - loss: 0.4712 - accuracy: 0.8696 - val_loss: 0.4163 - val_accuracy: 0.8932 - lr: 0.0200\n",
            "Epoch 14/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4709 - accuracy: 0.8697 - val_loss: 0.4163 - val_accuracy: 0.8928 - lr: 0.0200\n",
            "Epoch 15/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4708 - accuracy: 0.8692 - val_loss: 0.4145 - val_accuracy: 0.8927 - lr: 0.0200\n",
            "Epoch 16/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4668 - accuracy: 0.8702 - val_loss: 0.4180 - val_accuracy: 0.8935 - lr: 0.0200\n",
            "Epoch 17/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4662 - accuracy: 0.8713 - val_loss: 0.4147 - val_accuracy: 0.8928 - lr: 0.0200\n",
            "Epoch 18/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4665 - accuracy: 0.8710 - val_loss: 0.4146 - val_accuracy: 0.8932 - lr: 0.0200\n",
            "Epoch 19/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4673 - accuracy: 0.8712 - val_loss: 0.4163 - val_accuracy: 0.8944 - lr: 0.0200\n",
            "Epoch 20/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4643 - accuracy: 0.8712 - val_loss: 0.4176 - val_accuracy: 0.8937 - lr: 0.0200\n",
            "Epoch 21/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4610 - accuracy: 0.8723 - val_loss: 0.4160 - val_accuracy: 0.8940 - lr: 0.0040\n",
            "Epoch 22/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4631 - accuracy: 0.8712 - val_loss: 0.4158 - val_accuracy: 0.8937 - lr: 0.0040\n",
            "Epoch 23/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4637 - accuracy: 0.8716 - val_loss: 0.4161 - val_accuracy: 0.8934 - lr: 0.0040\n",
            "Epoch 24/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4616 - accuracy: 0.8721 - val_loss: 0.4166 - val_accuracy: 0.8935 - lr: 0.0040\n",
            "Epoch 25/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4624 - accuracy: 0.8712 - val_loss: 0.4151 - val_accuracy: 0.8940 - lr: 0.0040\n",
            "Epoch 26/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4580 - accuracy: 0.8737 - val_loss: 0.4162 - val_accuracy: 0.8939 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4617 - accuracy: 0.8723 - val_loss: 0.4155 - val_accuracy: 0.8939 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4654 - accuracy: 0.8720 - val_loss: 0.4152 - val_accuracy: 0.8939 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4593 - accuracy: 0.8719 - val_loss: 0.4157 - val_accuracy: 0.8938 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4630 - accuracy: 0.8718 - val_loss: 0.4154 - val_accuracy: 0.8937 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "3633/3633 [==============================] - 90s 25ms/step - loss: 0.4616 - accuracy: 0.8723 - val_loss: 0.4159 - val_accuracy: 0.8936 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4607 - accuracy: 0.8718 - val_loss: 0.4153 - val_accuracy: 0.8942 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4611 - accuracy: 0.8723 - val_loss: 0.4156 - val_accuracy: 0.8940 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4563 - accuracy: 0.8732 - val_loss: 0.4159 - val_accuracy: 0.8938 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4584 - accuracy: 0.8722 - val_loss: 0.4159 - val_accuracy: 0.8941 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4590 - accuracy: 0.8738 - val_loss: 0.4156 - val_accuracy: 0.8938 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4602 - accuracy: 0.8723 - val_loss: 0.4154 - val_accuracy: 0.8941 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4587 - accuracy: 0.8722 - val_loss: 0.4156 - val_accuracy: 0.8940 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4610 - accuracy: 0.8726 - val_loss: 0.4153 - val_accuracy: 0.8938 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4593 - accuracy: 0.8728 - val_loss: 0.4151 - val_accuracy: 0.8943 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4582 - accuracy: 0.8725 - val_loss: 0.4153 - val_accuracy: 0.8942 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4603 - accuracy: 0.8727 - val_loss: 0.4150 - val_accuracy: 0.8941 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4626 - accuracy: 0.8713 - val_loss: 0.4141 - val_accuracy: 0.8943 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4613 - accuracy: 0.8724 - val_loss: 0.4144 - val_accuracy: 0.8941 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4582 - accuracy: 0.8740 - val_loss: 0.4149 - val_accuracy: 0.8938 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4532 - accuracy: 0.8723 - val_loss: 0.4147 - val_accuracy: 0.8938 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4594 - accuracy: 0.8729 - val_loss: 0.4151 - val_accuracy: 0.8941 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "3633/3633 [==============================] - 89s 24ms/step - loss: 0.4664 - accuracy: 0.8711 - val_loss: 0.4145 - val_accuracy: 0.8939 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "3633/3633 [==============================] - 89s 25ms/step - loss: 0.4611 - accuracy: 0.8726 - val_loss: 0.4139 - val_accuracy: 0.8942 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4610 - accuracy: 0.8727 - val_loss: 0.4143 - val_accuracy: 0.8942 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.evaluate(test_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCRFHILLNXCG",
        "outputId": "577230f6-e84e-4c66-fc86-14a9ea0b4bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1041/1041 [==============================] - 11s 10ms/step - loss: 0.3637 - accuracy: 0.9072\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.36368489265441895, 0.9072065949440002]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.load_weights('train_weights2.h5')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=5, min_lr=0.01)\n",
        "history2=classifier.fit(train_set, steps_per_epoch = len(train_set), epochs = 50,\n",
        "                        validation_data = val_set, validation_steps = len(val_set))\n",
        "classifier.save_weights('train_weights3.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUkRxLstNW8e",
        "outputId": "0f0d79ea-10fd-4f6c-8fca-bb798b1b561a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4600 - accuracy: 0.8725 - val_loss: 0.4144 - val_accuracy: 0.8938\n",
            "Epoch 2/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4582 - accuracy: 0.8729 - val_loss: 0.4144 - val_accuracy: 0.8941\n",
            "Epoch 3/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4563 - accuracy: 0.8730 - val_loss: 0.4152 - val_accuracy: 0.8941\n",
            "Epoch 4/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4611 - accuracy: 0.8714 - val_loss: 0.4150 - val_accuracy: 0.8938\n",
            "Epoch 5/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4625 - accuracy: 0.8717 - val_loss: 0.4150 - val_accuracy: 0.8943\n",
            "Epoch 6/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4631 - accuracy: 0.8709 - val_loss: 0.4145 - val_accuracy: 0.8942\n",
            "Epoch 7/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4578 - accuracy: 0.8733 - val_loss: 0.4142 - val_accuracy: 0.8940\n",
            "Epoch 8/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4600 - accuracy: 0.8734 - val_loss: 0.4148 - val_accuracy: 0.8943\n",
            "Epoch 9/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4609 - accuracy: 0.8715 - val_loss: 0.4145 - val_accuracy: 0.8942\n",
            "Epoch 10/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4611 - accuracy: 0.8718 - val_loss: 0.4147 - val_accuracy: 0.8936\n",
            "Epoch 11/50\n",
            "3633/3633 [==============================] - 89s 24ms/step - loss: 0.4616 - accuracy: 0.8726 - val_loss: 0.4147 - val_accuracy: 0.8935\n",
            "Epoch 12/50\n",
            "3633/3633 [==============================] - 90s 25ms/step - loss: 0.4577 - accuracy: 0.8726 - val_loss: 0.4147 - val_accuracy: 0.8940\n",
            "Epoch 13/50\n",
            "3633/3633 [==============================] - 89s 24ms/step - loss: 0.4609 - accuracy: 0.8719 - val_loss: 0.4144 - val_accuracy: 0.8941\n",
            "Epoch 14/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4581 - accuracy: 0.8727 - val_loss: 0.4140 - val_accuracy: 0.8944\n",
            "Epoch 15/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4593 - accuracy: 0.8735 - val_loss: 0.4141 - val_accuracy: 0.8942\n",
            "Epoch 16/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4597 - accuracy: 0.8721 - val_loss: 0.4144 - val_accuracy: 0.8942\n",
            "Epoch 17/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4609 - accuracy: 0.8728 - val_loss: 0.4141 - val_accuracy: 0.8940\n",
            "Epoch 18/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4593 - accuracy: 0.8725 - val_loss: 0.4142 - val_accuracy: 0.8944\n",
            "Epoch 19/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4569 - accuracy: 0.8739 - val_loss: 0.4144 - val_accuracy: 0.8940\n",
            "Epoch 20/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4584 - accuracy: 0.8735 - val_loss: 0.4141 - val_accuracy: 0.8940\n",
            "Epoch 21/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4585 - accuracy: 0.8722 - val_loss: 0.4142 - val_accuracy: 0.8937\n",
            "Epoch 22/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4579 - accuracy: 0.8726 - val_loss: 0.4140 - val_accuracy: 0.8940\n",
            "Epoch 23/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4610 - accuracy: 0.8716 - val_loss: 0.4136 - val_accuracy: 0.8940\n",
            "Epoch 24/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4616 - accuracy: 0.8720 - val_loss: 0.4142 - val_accuracy: 0.8939\n",
            "Epoch 25/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4601 - accuracy: 0.8725 - val_loss: 0.4138 - val_accuracy: 0.8941\n",
            "Epoch 26/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4606 - accuracy: 0.8724 - val_loss: 0.4137 - val_accuracy: 0.8938\n",
            "Epoch 27/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4601 - accuracy: 0.8723 - val_loss: 0.4136 - val_accuracy: 0.8941\n",
            "Epoch 28/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4589 - accuracy: 0.8721 - val_loss: 0.4141 - val_accuracy: 0.8941\n",
            "Epoch 29/50\n",
            "3633/3633 [==============================] - 89s 24ms/step - loss: 0.4553 - accuracy: 0.8736 - val_loss: 0.4147 - val_accuracy: 0.8946\n",
            "Epoch 30/50\n",
            "3633/3633 [==============================] - 89s 24ms/step - loss: 0.4582 - accuracy: 0.8729 - val_loss: 0.4143 - val_accuracy: 0.8943\n",
            "Epoch 31/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4615 - accuracy: 0.8723 - val_loss: 0.4137 - val_accuracy: 0.8945\n",
            "Epoch 32/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4618 - accuracy: 0.8721 - val_loss: 0.4143 - val_accuracy: 0.8941\n",
            "Epoch 33/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4589 - accuracy: 0.8725 - val_loss: 0.4138 - val_accuracy: 0.8939\n",
            "Epoch 34/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4576 - accuracy: 0.8744 - val_loss: 0.4140 - val_accuracy: 0.8940\n",
            "Epoch 35/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4549 - accuracy: 0.8743 - val_loss: 0.4146 - val_accuracy: 0.8939\n",
            "Epoch 36/50\n",
            "3633/3633 [==============================] - 89s 24ms/step - loss: 0.4580 - accuracy: 0.8727 - val_loss: 0.4144 - val_accuracy: 0.8944\n",
            "Epoch 37/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4578 - accuracy: 0.8721 - val_loss: 0.4145 - val_accuracy: 0.8940\n",
            "Epoch 38/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4616 - accuracy: 0.8714 - val_loss: 0.4136 - val_accuracy: 0.8941\n",
            "Epoch 39/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4599 - accuracy: 0.8729 - val_loss: 0.4144 - val_accuracy: 0.8939\n",
            "Epoch 40/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4573 - accuracy: 0.8731 - val_loss: 0.4144 - val_accuracy: 0.8943\n",
            "Epoch 41/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4590 - accuracy: 0.8723 - val_loss: 0.4146 - val_accuracy: 0.8941\n",
            "Epoch 42/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4559 - accuracy: 0.8742 - val_loss: 0.4138 - val_accuracy: 0.8941\n",
            "Epoch 43/50\n",
            "3633/3633 [==============================] - 89s 25ms/step - loss: 0.4571 - accuracy: 0.8727 - val_loss: 0.4141 - val_accuracy: 0.8946\n",
            "Epoch 44/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4600 - accuracy: 0.8726 - val_loss: 0.4141 - val_accuracy: 0.8944\n",
            "Epoch 45/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4547 - accuracy: 0.8728 - val_loss: 0.4144 - val_accuracy: 0.8946\n",
            "Epoch 46/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4577 - accuracy: 0.8727 - val_loss: 0.4140 - val_accuracy: 0.8947\n",
            "Epoch 47/50\n",
            "3633/3633 [==============================] - 88s 24ms/step - loss: 0.4578 - accuracy: 0.8719 - val_loss: 0.4139 - val_accuracy: 0.8946\n",
            "Epoch 48/50\n",
            "3633/3633 [==============================] - 89s 25ms/step - loss: 0.4595 - accuracy: 0.8725 - val_loss: 0.4137 - val_accuracy: 0.8941\n",
            "Epoch 49/50\n",
            "3633/3633 [==============================] - 87s 24ms/step - loss: 0.4595 - accuracy: 0.8725 - val_loss: 0.4139 - val_accuracy: 0.8944\n",
            "Epoch 50/50\n",
            "3633/3633 [==============================] - 89s 24ms/step - loss: 0.4560 - accuracy: 0.8733 - val_loss: 0.4142 - val_accuracy: 0.8944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.evaluate(test_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqDdkr4sis0i",
        "outputId": "79cc6567-c6a6-4501-9a62-d39cde15fc39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1041/1041 [==============================] - 11s 10ms/step - loss: 0.3636 - accuracy: 0.9074\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3635816276073456, 0.9073567986488342]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bjN5gNnTNW0P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
